# IE - Master in Business Analytics and Big Data
Recommendation Systems

Evaluation Methods 

Author: Ivan Tarradellas Olmo

========================================================

# Initialization

Import libraries

```{r}
library(DescTools)
library(rrecsys)
```

```{r}
# ordered vector of predicted movie ratings and real ratings for sophia, maria and ivan
sophia_pred = c(4.20,3.98,3.97,3.09,2.66)
sophia_real = c(3,4,4,3,3)

maria_pred = c(4.99,4.77,3.98,3.87,3.23)
maria_real = c(5,5,4,4,3)

ivan_pred = c(4.86,4.85,3.85,3.74,3.23,3.13,2.90,2.89,1.87,1.66,0.65,0.44)
ivan_real = c(5,5,4,4,1,1,5,5,5,5,5,4)
```

# 1) Evaluating predictions (MAE, MSE, RMSE) using Error ratings average
Combine all users predictions and observations and calculate the MAE, the MSE and the RMSE. 
Use : MAE(real,pred,na.rm.T)
What's the system status?

```{r fig.width=7, fig.height=6}
# Combine all users in one vector
all_real <- c(sophia_real,maria_real,ivan_real)
all_pred <- c(sophia_pred,maria_pred,ivan_pred)

sprintf("Mean Absolute Error: %s", MAE(all_real,all_pred, na.rm = T))
sprintf("Mean Square Error: %s",MSE(all_real,all_pred, na.rm = T))
sprintf("Root Mean Square Error: %s",RMSE(all_real,all_pred, na.rm = T))
```

# 2) Evaluating Users ratings average predictions, only considering RMSE
Calculate the users ratings RMSE average. Consider each user's RSME separately and then do the average of the 3 RMSEs. 
What this discrepancy means with the previous RMSE? Compare Sophia RMSE with Ivan RMSE, what it means?
```{r fig.width=7, fig.height=6}
rmse_sophia <- RMSE(sophia_real, sophia_pred, na.rm = T) ;
rmse_sophia ;
rmse_maria <- RMSE(maria_real, maria_pred, na.rm = T) ;
rmse_maria ;
rmse_ivan <- RMSE(ivan_real, ivan_pred, na.rm = T) ;
rmse_ivan;

mean(c(rmse_ivan,rmse_maria,rmse_sophia))
```

# 3) Evaluating Ranking - Mean Reciprocal Rank (MRR) 
Calculate the MRR for Sophia. Compare it with Ivan's MRR. 
Note: Consider a movie rating >= 4 as a like. 
What it means?
```{r fig.width=7, fig.height=6}
mrr <- function(x){
  1/which(x>=4)[1]
}
# you use mrr when prediction is odered, and the real is ordered based on the predicition
sprintf("sophias MRR: %s", mrr(sophia_real))
sprintf("Ivan's MRR: %s", mrr(ivan_real))
```

# 4) Evaluating Ranking - Spearman Rank Correlation (SPR)
Calculate the SPR for Sophia. Compare it with Ivan's SPR. 
What it means?
```{r fig.width=7, fig.height=6}
sprintf("sophia spearman corr: %s",cor(sophia_pred, sophia_real, method="spearman"))
sprintf("ivan spearman corr: %s",cor(ivan_pred, ivan_real, method = "spearman"))
```
```{r}

cor(order(sophia_pred, decreasing = T),rank(-sophia_real,ties.method = "average"), method = "pearson")

```


# 5) Evaluating Ranking - Discounted Cumulative Gain (DCG)
Calculate the DGC for Sophia. Compare it with Ivan's DGC. 
What it means?
```{r fig.width=7, fig.height=6}
# Basic decay function per position
decay = function(position) {
  return(1/position)
}


# Basic utility function considering the rating of the item
utility = function(item) {
  return(item)
}
# Discounted Cumulative Gain of a given vector, considering the utility function as
dcg = function(data) {
  result <- 0
  for(ii in 1:length(data)){
    result <- result +(utility(data[ii])*decay(ii))
  }
  
  return(result)# Tbd
}

nDCG_sophia <- dcg(sophia_pred)/dcg(sophia_real)
nDCG_sophia

nDCG_Ivan <- dcg(ivan_pred)/dcg(ivan_real)
nDCG_Ivan
# Tbd
```