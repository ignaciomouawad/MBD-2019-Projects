rmse_maria
rmse_ivan <- RMSE(ivan_real, ivan_pred, na.rm = T)
rmse_ivan
?MRR
??MRR
mean(rmse_ivan,rmse_maria,rmse_sophia)
rmse_sophia <- RMSE(sophia_real, sophia_pred, na.rm = T)
rmse_sophia
rmse_maria <- RMSE(maria_real, maria_pred, na.rm = T)
rmse_maria
rmse_ivan <- RMSE(ivan_real, ivan_pred, na.rm = T)
rmse_ivan
mean(rmse_ivan,rmse_maria,rmse_sophia)
?RMSE
rmse_sophia <- RMSE(sophia_real, sophia_pred, na.rm = T)
rmse_sophia
rmse_maria <- RMSE(maria_real, maria_pred, na.rm = T)
rmse_maria
rmse_ivan <- RMSE(ivan_real, ivan_pred, na.rm = T)
rmse_ivan
mean(rmse_ivan,rmse_maria,rmse_sophia)
# ordered vector of predicted movie ratings and real ratings for sophia, maria and ivan
sophia_pred = c(4.20,3.98,3.97,3.09,2.66)
sophia_real = c(3,4,4,3,3)
maria_pred = c(4.99,4.77,3.98,3.87,3.23)
maria_real = c(5,5,4,4,3)
ivan_pred = c(4.86,4.85,3.85,3.74,3.23,3.13,2.90,2.89,1.87,1.66,0.65,0.44)
ivan_real = c(5,5,4,4,1,1,5,5,5,5,5,4)
# Combine all users in one vector
all_real <- c(sophia_real,maria_real,ivan_real)
all_pred <- c(sophia_pred,maria_pred,ivan_pred)
MAE(all_real,all_pred, na.rm = T)
MSE(all_real,all_pred, na.rm = T)
RMSE(all_real,all_pred, na.rm = T)
rmse_sophia <- RMSE(sophia_real, sophia_pred, na.rm = T)
rmse_sophia
rmse_maria <- RMSE(maria_real, maria_pred, na.rm = T)
rmse_maria
rmse_ivan <- RMSE(ivan_real, ivan_pred, na.rm = T)
rmse_ivan
mean(rmse_ivan,rmse_maria,rmse_sophia)
mean(rmse_ivan,rmse_maria,rmse_sophia)
RMSE(ivan_real, ivan_pred, na.rm = T)
RMSE(maria_real, maria_pred, na.rm = T)
RMSE(sophia_real, sophia_pred, na.rm = T)
rmse_sophia <- RMSE(sophia_real, sophia_pred, na.rm = T)
rmse_sophia
rmse_maria <- RMSE(maria_real, maria_pred, na.rm = T)
rmse_maria
rmse_ivan <- RMSE(ivan_real, ivan_pred, na.rm = T)
rmse_ivan
mean(c(rmse_ivan,rmse_maria,rmse_sophia))
sprintf("Mean Absolute Error: %s", MAE)
s <- MAE(all_real,all_pred, na.rm = T)
sprintf("Mean Absolute Error: %s", s)
sprintf("Mean Absolute Error: %s", MAE(all_real,all_pred, na.rm = T))
# Combine all users in one vector
all_real <- c(sophia_real,maria_real,ivan_real)
all_pred <- c(sophia_pred,maria_pred,ivan_pred)
sprintf("Mean Absolute Error: %s", MAE(all_real,all_pred, na.rm = T))
sprintf("Mean Square Error: %s",MSE(all_real,all_pred, na.rm = T))
sprintf("Root Mean Square Error: %s",RMSE(all_real,all_pred, na.rm = T)
# Combine all users in one vector
all_real <- c(sophia_real,maria_real,ivan_real)
all_pred <- c(sophia_pred,maria_pred,ivan_pred)
sprintf("Mean Absolute Error: %s", MAE(all_real,all_pred, na.rm = T))
sprintf("Mean Square Error: %s",MSE(all_real,all_pred, na.rm = T))
sprintf("Root Mean Square Error: %s",RMSE(all_real,all_pred, na.rm = T))
# ordered vector of predicted movie ratings and real ratings for sophia, maria and ivan
sophia_pred = c(4.20,3.98,3.97,3.09,2.66)
sophia_real = c(3,4,4,3,3)
maria_pred = c(4.99,4.77,3.98,3.87,3.23)
maria_real = c(5,5,4,4,3)
ivan_pred = c(4.86,4.85,3.85,3.74,3.23,3.13,2.90,2.89,1.87,1.66,0.65,0.44)
ivan_real = c(5,5,4,4,1,1,5,5,5,5,5,4)
# Combine all users in one vector
all_real <- c(sophia_real,maria_real,ivan_real)
all_pred <- c(sophia_pred,maria_pred,ivan_pred)
sprintf("Mean Absolute Error: %s", MAE(all_real,all_pred, na.rm = T))
sprintf("Mean Square Error: %s",MSE(all_real,all_pred, na.rm = T))
sprintf("Root Mean Square Error: %s",RMSE(all_real,all_pred, na.rm = T))
rmse_sophia <- RMSE(sophia_real, sophia_pred, na.rm = T)
rmse_sophia
rmse_maria <- RMSE(maria_real, maria_pred, na.rm = T)
rmse_maria
rmse_ivan <- RMSE(ivan_real, ivan_pred, na.rm = T)
rmse_ivan
mean(c(rmse_ivan,rmse_maria,rmse_sophia))
rmse_sophia <- RMSE(sophia_real, sophia_pred, na.rm = T) ;
rmse_sophia ;
rmse_maria <- RMSE(maria_real, maria_pred, na.rm = T) ;
rmse_maria ;
rmse_ivan <- RMSE(ivan_real, ivan_pred, na.rm = T) ;
rmse_ivan;
mean(c(rmse_ivan,rmse_maria,rmse_sophia))
which(sophia_pred>4)
which(sophia_real>4)
which(sophia_real>4)
which(sophia_real>=4)
which(sophia_real>=4)[1]
mrr <- function(x){
1/which(x>=4)[1]
}
sprintf("sophias MRR: %s", mrr(sophia_real))
sprintf("Ivan's MRR: %s", mrr(ivan_real))
mrr <- function(x){
1/which(x>=4)[1]
}
# you use mrr when prediction is odered, and the real is ordered based on the predicition
sprintf("sophias MRR: %s", mrr(sophia_real))
sprintf("Ivan's MRR: %s", mrr(ivan_real))
cor(sophia_pred, sophia_real, type="spearman")
?cor
?cor(sophia_pred, sophia_real, method="spearman")
cor(sophia_pred, sophia_real, method="spearman")
cor(sophia_pred, sophia_real, method="spearman")
cor(ivan_pred, ivan_real, method = "spearman")
sprint("sophia spearman corr: %s",cor(sophia_pred, sophia_real, method="spearman"))
sprintf("sophia spearman corr: %s",cor(sophia_pred, sophia_real, method="spearman"))
sprintf("sophia spearman corr: %s",cor(ivan_pred, ivan_real, method = "spearman"))
sprintf("sophia spearman corr: %s",cor(sophia_pred, sophia_real, method="spearman"))
sprintf("ivan spearman corr: %s",cor(ivan_pred, ivan_real, method = "spearman"))
order(sophia_real)
rankScore(sophia_pred,sophia_real)
rank(-sophia_pred,ties.method = "average")
rank(-sophia_real,ties.method = "average")
cor(order(sophia_real),rank(-sophia_real,ties.method = "average")
cor(order(sophia_real),rank(-sophia_real,ties.method = "average"), method = "spearman")
order(sophia_real)
rank(-sophia_real,ties.method = "average")
cor(order(sophia_real),rank(-sophia_real,ties.method = "average"), method = "spearman")
sophia_pred = c(4.20,3.98,3.97,3.09,2.66)
sophia_real = c(3,4,4,3,3)
rankScore(sophia_pred,sophia_real)
cor(order(sophia_real, decreasing = T),rank(-sophia_real,ties.method = "average"), method = "spearman")
cor(order(sophia_pred, decreasing = T),rank(-sophia_real,ties.method = "average"), method = "spearman")
cor(order(sophia_pred, decreasing = T),rank(-sophia_real,ties.method = "average"), method = "pearson")
# Basic decay function per position
decay = function(position) {
return(1/position)
}
# Basic utility function considering the rating of the item
utility = function(item) {
return(item)
}
# Discounted Cumulative Gain of a given vector, considering the utility function as
dcg = function(data) {
# Tbd
}
# Tbd
# Basic decay function per position
decay = function(position) {
return(1/position)
}
# Basic utility function considering the rating of the item
utility = function(item) {
return(item)
}
# Discounted Cumulative Gain of a given vector, considering the utility function as
dcg = function(data) {
result <- 0
for(ii in 1:length(data)){
result <- result +(utility(data[ii])*decay(ii))
}
# Tbd
}
nDCG_sophia <- dcg(sophia_pred)/dcg(sophia_real)
nDCG_sophia
# Basic decay function per position
decay = function(position) {
return(1/position)
}
# Basic utility function considering the rating of the item
utility = function(item) {
return(item)
}
# Discounted Cumulative Gain of a given vector, considering the utility function as
dcg = function(data) {
result <- 0
for(ii in 1:length(data)){
result <- result +(utility(data[ii])*decay(ii))
}
return(result)# Tbd
}
nDCG_sophia <- dcg(sophia_pred)/dcg(sophia_real)
nDCG_sophia
# Tbd
# Basic decay function per position
decay = function(position) {
return(1/position)
}
# Basic utility function considering the rating of the item
utility = function(item) {
return(item)
}
# Discounted Cumulative Gain of a given vector, considering the utility function as
dcg = function(data) {
result <- 0
for(ii in 1:length(data)){
result <- result +(utility(data[ii])*decay(ii))
}
return(result)# Tbd
}
nDCG_sophia <- dcg(sophia_pred)/dcg(sophia_real)
nDCG_sophia
nDCG_Ivan <- dcg(ivan_pred).dcg(ivan_real)
# Basic decay function per position
decay = function(position) {
return(1/position)
}
# Basic utility function considering the rating of the item
utility = function(item) {
return(item)
}
# Discounted Cumulative Gain of a given vector, considering the utility function as
dcg = function(data) {
result <- 0
for(ii in 1:length(data)){
result <- result +(utility(data[ii])*decay(ii))
}
return(result)# Tbd
}
nDCG_sophia <- dcg(sophia_pred)/dcg(sophia_real)
nDCG_sophia
nDCG_Ivan <- dcg(ivan_pred)/dcg(ivan_real)
# Tbd
# Basic decay function per position
decay = function(position) {
return(1/position)
}
# Basic utility function considering the rating of the item
utility = function(item) {
return(item)
}
# Discounted Cumulative Gain of a given vector, considering the utility function as
dcg = function(data) {
result <- 0
for(ii in 1:length(data)){
result <- result +(utility(data[ii])*decay(ii))
}
return(result)# Tbd
}
nDCG_sophia <- dcg(sophia_pred)/dcg(sophia_real)
nDCG_sophia
nDCG_Ivan <- dcg(ivan_pred)/dcg(ivan_real)
nDCG_Ivan
# Tbd
install.packages("rpart.plot")
knitr::opts_chunk$set(echo = TRUE)
set.seed(123)
library(MASS)
library(caret)
library(rpart)
library(rpart.plot)
original_wine <- read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data",header=F)
attach(original_wine)
summary(original_wine)
preprocessParams = preProcess(original_wine[ ,2:14], method=c("center", "scale", "BoxCox"))
wine_pca <- predict(preprocessParams, original_wine[, 2:14])
summary(wine_pca)
pca <- prcomp(wine_pca)
summary(pca)
plot(cumsum((pca$sdev^2)/sum(pca$sdev^2)), type="b", col="blue", lwd=2, xlim=c(1,13),
main="Cum. proportion of Variance", xlab="# of PC", ylab="Cumulative Variance")
plot(cumsum((pca$sdev^2)/sum(pca$sdev^2)), type="b", col="blue", lwd=2, xlim=c(0,14),
main="Cum. proportion of Variance", xlab="# of PC", ylab="Cumulative Variance")
abline(h=0.75, col="red", lty=2, lwd=2)
bp <- barplot(pca$sdev^2, xlab="Nr. of PC", ylab="Variance", main="Variance per PC", col="light blue")
axis(side=1, at=bp, labels=c(1:13))
abline(h=1, col="red", lwd=2, lty=2)
plot(pca$x[,1], pca$x[,2], col=V1+1, pch=20)
pca$rotation
pca$rotation[,1:4]
wine_pca[1,]
w_pc<-as.matrix(wine_pca)%*%as.matrix(pca$rotation[,1:4])
w_pc[1,]
wine_pca_5pc <-as.data.frame(cbind(V1,w_pc))
trainIndex = createDataPartition(wine_pca_5pc$V1, p=0.7, list=FALSE, times=1)
train = wine_pca_5pc[trainIndex,]
test = wine_pca_5pc[-trainIndex,]
tree_model0 <- rpart(V1~., data=train, method="class")
tree_model0$variable.importance
rpart.plot(tree_model0, type = 1, fallen.leaves = F, extra = 4)
predictions <- predict(tree_model0, test)
confusionMatrix(as.factor(apply(predictions,1,which.max)),as.factor(test$V1))
wine = cbind(V1, wine_pca)
trainIndex = createDataPartition(wine$V1, p=0.7, list=FALSE, times=1)
train = wine[trainIndex,]
test = wine[-trainIndex,]
tree_model0 <- rpart(V1~., data=train, method="class")
tree_model0$variable.importance
rpart.plot(tree_model0, type = 1, fallen.leaves = F, extra = 4)
predictions <- predict(tree_model0, test)
confusionMatrix(as.factor(apply(predictions,1,which.max)),as.factor(test$V1))
tree_model1 <- train(as.factor(V1) ~ .,
method="rpart",
preProcess=c("pca"), # We have already center, scale and remove skewness from the data before (it is needed to apply PCA) and now we apply pca
metric = "Accuracy",
data=train)
tree_model1
rpart.plot(tree_model1$finalModel, type = 1, fallen.leaves = F, extra = 4)
confusionMatrix(as.factor(test$V1), predict(tree_model1,test))
for (i in 1:ncol(train)){
tree_model2 <- train(as.factor(V1) ~ .,
method="rpart",
data=train,
preProcess=c("pca"), # We have already center, scale and remove skewness from the data before (it is needed to apply PCA) and now we apply pca
metric = "Accuracy",
trControl = trainControl(preProcOptions = list(pcaComp=i)))
# rpart.plot(tree_model2$finalModel, type = 1, fallen.leaves = F, extra = 4)
cat("Accuracy of model with", i, "Principal Components", confusionMatrix(as.factor(test$V1), predict(tree_model2,test))$overall["Accuracy"], "\n")
}
knitr::opts_chunk$set(echo = TRUE)
set.seed(4321)
dataset <- read.csv("./data.csv")
# Collecth the features
dataset.features <- as.matrix(dataset[,c(3:32)])
# Set the row names
row.names(dataset.features) <- dataset$id
# Create diagnosis vector
diagnosis <- as.numeric(dataset$diagnosis == "M")
table(dataset$diagnosis)
library(corrplot)
corMatrix <- dataset[,c(3:32)]
corrplot(cor(corMatrix), type = "upper")
# Your code here
cex.before <- par("cex")
par(cex = 0.7)
# Take a look to the biplot function
# Set up 1 x 2 plotting grid
par(mfrow = c(1, 2))
# Calculate variability of each component
# pr.var <- Your Code here!
# pve <- pr.var/sum(pr.var)
# Your code here
# Your code here
# Your code here
# Your code here
library(MASS)
# convert matrix to a dataframe
# Perform LDA on diagnosis
# convert matrix to a dataframe
# Predict using the computed LDA model
knitr::opts_chunk$set(echo = TRUE)
set.seed(4321)
dataset <- read.csv("./data.csv")
# Collecth the features
dataset.features <- as.matrix(dataset[,c(3:32)])
# Set the row names
row.names(dataset.features) <- dataset$id
# Create diagnosis vector
diagnosis <- as.numeric(dataset$diagnosis == "M")
table(dataset$diagnosis)
library(corrplot)
corMatrix <- dataset[,c(3:32)]
corrplot(cor(corMatrix), type = "upper")
# Your code here
cex.before <- par("cex")
par(cex = 0.7)
# Take a look to the biplot function
# Set up 1 x 2 plotting grid
par(mfrow = c(1, 2))
# Calculate variability of each component
# pr.var <- Your Code here!
# pve <- pr.var/sum(pr.var)
# Your code here
# Your code here
# Your code here
# Your code here
library(MASS)
# convert matrix to a dataframe
# Perform LDA on diagnosis
# convert matrix to a dataframe
# Predict using the computed LDA model
library("ROCR")
# Evaluate the model
# Your code here
# Your code here
View(dataset)
summary(dataset)
as.matrix(dataset[,c(3:32)])
knitr::opts_chunk$set(echo = TRUE)
set.seed(4321)
dataset <- read.csv("./data.csv")
head(dataset)
# Collect the features
ncol(dataset)
# Collect the features
dataset.features <- as.matrix(dataset[,c(3:32)])
# Set the row names
row.names(dataset.features) <- dataset$id
# Create diagnosis vector
diagnosis <- as.numeric(dataset$diagnosis == "M")
table(dataset$diagnosis)
sapply(dataset.features,hist)
print("x")
library(caret)
library(data.table)
library(caret)
library(data.table)
dataset <- read.csv("./data.csv")
preprcosessParams = preProcess(dataset.features, method = c("center","scale","BoxCox"))
library(caret)
library(data.table)
dataset <- read.csv("./data.csv")
# Collect the features
dataset.features <- as.matrix(dataset[,c(3:32)])
# Set the row names
row.names(dataset.features) <- dataset$id
# Create diagnosis vector
diagnosis <- as.numeric(dataset$diagnosis == "M")
table(dataset$diagnosis)
preprcosessParams = preProcess(dataset.features, method = c("center","scale","BoxCox"))
preprcosessParams <- preProcess(dataset.features, method = c("center","scale","BoxCox"))
preprcosessParams <- preProcess(dataset.features, method = c("center","scale","BoxCox"))
summary(preprcosessParams)
# Your code here
prcomp(preprcosessParams)
preprcosessParams
dataset_pca <-  predict(preprocessParams, dataset.features)
preprocessParams <- preProcess(dataset.features, method = c("center","scale","BoxCox"))
dataset_pca <-  predict(preprocessParams, dataset.features)
summary(preprocessParams)
preprocessParams <- preProcess(dataset.features, method = c("center","scale","BoxCox"))
dataset_pca <-  predict(preprocessParams, dataset.features)
summary(dataset_pca)
library(corrplot)
corMatrix <- dataset[,c(3:32)]
corrplot(cor(corMatrix), type = "upper")
```{r}
preprocessParams <- preProcess(dataset.features, method = c("center","scale","BoxCox"))
dataset_pca <-  predict(preprocessParams, dataset.features)
summary(dataset_pca)
# Your code here
prcomp(dataset_pca)
# Your code here
pca<-prcomp(dataset_pca)
summary(pca)
cex.before <- par("cex")
par(cex = 0.7)
# Take a look to the biplot function
cex.before <- par("cex")
par(cex = 0.7)
# Take a look to the biplot function
biplot(pca, cex.before)
par(cex = 0.7)
# Take a look to the biplot function
biplot(pca)
# Set up 1 x 2 plotting grid
par(mfrow = c(1, 2))
# pr.var <- Your Code here!
princomp(pca)
# pr.var <- Your Code here!
princomp(dataset_pca)
pca
# Your code here
pca<-prcomp(dataset_pca)
summary(pca)
# pr.var <- Your Code here!
princomp(dataset_pca).var
library(DescTools)
library(rrecsys)
# ordered vector of predicted movie ratings and real ratings for sophia, maria and ivan
sophia_pred = c(4.20,3.98,3.97,3.09,2.66)
sophia_real = c(3,4,4,3,3)
maria_pred = c(4.99,4.77,3.98,3.87,3.23)
maria_real = c(5,5,4,4,3)
ivan_pred = c(4.86,4.85,3.85,3.74,3.23,3.13,2.90,2.89,1.87,1.66,0.65,0.44)
ivan_real = c(5,5,4,4,1,1,5,5,5,5,5,4)
# Combine all users in one vector
all_real <- c(sophia_real,maria_real,ivan_real)
all_pred <- c(sophia_pred,maria_pred,ivan_pred)
sprintf("Mean Absolute Error: %s", MAE(all_real,all_pred, na.rm = T))
sprintf("Mean Square Error: %s",MSE(all_real,all_pred, na.rm = T))
sprintf("Root Mean Square Error: %s",RMSE(all_real,all_pred, na.rm = T))
rmse_sophia <- RMSE(sophia_real, sophia_pred, na.rm = T) ;
rmse_sophia ;
rmse_maria <- RMSE(maria_real, maria_pred, na.rm = T) ;
rmse_maria ;
rmse_ivan <- RMSE(ivan_real, ivan_pred, na.rm = T) ;
rmse_ivan;
mean(c(rmse_ivan,rmse_maria,rmse_sophia))
sprintf("sophia spearman corr: %s",cor(sophia_pred, sophia_real, method="spearman"))
sprintf("ivan spearman corr: %s",cor(ivan_pred, ivan_real, method = "spearman"))
# Basic decay function per position
decay = function(position) {
return(1/position)
}
# Basic utility function considering the rating of the item
utility = function(item) {
return(item)
}
# Discounted Cumulative Gain of a given vector, considering the utility function as
dcg = function(data) {
result <- 0
for(ii in 1:length(data)){
result <- result +(utility(data[ii])*decay(ii))
}
return(result)# Tbd
}
nDCG_sophia <- dcg(sophia_pred)/dcg(sophia_real)
nDCG_sophia
nDCG_Ivan <- dcg(ivan_pred)/dcg(ivan_real)
nDCG_Ivan
# Tbd
sophia_pred = c(5,4,3,2,1)
sophia_real = c(1,5,4,2,3)
mrr <- function(x){
1/which(x>=4)[1]
}
# you use mrr when prediction is odered, and the real is ordered based on the predicition
sprintf("sophias MRR: %s", mrr(sophia_real))
