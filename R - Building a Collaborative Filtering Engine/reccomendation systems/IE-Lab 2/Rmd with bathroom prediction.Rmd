---
title: "Recommendation Engines Quora"
author: "ignacio"
date: "10/12/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(lsa)
question_topics <- read.csv("C:\\Users/ignac/Desktop/ie/mbd term 2/reccomendation systems/IE-Lab 2/Problem/questiontopics.csv")
feedback <- read.csv("C:\\Users/ignac/Desktop/ie/mbd term 2/reccomendation systems/IE-Lab 2/Problem/userfeedback.csv")
answers <- read.csv("C:\\Users/ignac/Desktop/ie/mbd term 2/reccomendation systems/IE-Lab 2/Problem/useranswers.csv")


answers<-answers[1:4]
feedback<-feedback[1:4]
rownames(question_topics) <- question_topics$X

question_topics$X<-NULL
rownames(answers)<-rownames(question_topics)
rownames(feedback)<- rownames(question_topics)

question_answer <- sort(rowMeans(answers, na.rm = T), decreasing = T)
question_answer
question_feedback <- mean_ratings <- sort(rowMeans(feedback, na.rm = T), decreasing = T)
question_feedback

```

## Simple Unary
### user profile
```{r}
simple_unary_user_profile <- data.frame()
for(k in 1:ncol(feedback)){
  j<- vector()
  for(i in 1:ncol(question_topics)){
    j[i]<- sum(question_topics[,i]*feedback[,k], na.rm = T)
  }
  simple_unary_user_profile<-rbind(simple_unary_user_profile,j)

}

colnames(simple_unary_user_profile)<-colnames(question_topics)
rownames(simple_unary_user_profile) <- colnames(feedback)
simple_unary_user_profile
```
### calculating predictions

```{r}
unary_predict_table <- data.frame()


for(i in 1:nrow(simple_unary_user_profile)){
  for(k in 1:nrow(question_topics)){
    unary_predict_table[k,i]<- cosine(as.numeric(question_topics[k,]),as.numeric(simple_unary_user_profile[i,]))
  
  }
}
colnames(unary_predict_table) <- rownames(simple_unary_user_profile)
unary_predict_table

```

### likes tables 
```{r}

likes_dislikes <- rbind(sapply(unary_predict_table, function(x){sum(x>0)}))
likes_dislikes <- rbind(likes_dislikes,sapply(unary_predict_table, function(x){sum(x<0)}))
likes_dislikes <- rbind(likes_dislikes,sapply(unary_predict_table, function(x){sum(x==0)}))
rownames(likes_dislikes) <- c("likes", "dislikes","neutral")
likes_dislikes
```

## Unit Weight
### user profile
```{r}
CB_unit_weight <- data.frame()


for(k in 1:nrow(question_topics)){
  for(i in 1:ncol(question_topics)){
    CB_unit_weight[k,i] <- question_topics[k,i]/sum(question_topics[k,]) 
  }
}

unit_weight_user_profile <- data.frame()
for(k in 1:ncol(feedback)){
  j<- vector()
  for(i in 1:ncol(CB_unit_weight)){
    j[i]<- sum(CB_unit_weight[,i]*feedback[,k], na.rm = T)
  }
  unit_weight_user_profile<-rbind(unit_weight_user_profile,j)
  
}

colnames(unit_weight_user_profile)<-colnames(question_topics)
rownames(unit_weight_user_profile) <- colnames(feedback)
unit_weight_user_profile
```
### predictions
```{r}
unit_weight_predict_table <- data.frame()


for(i in 1:nrow(unit_weight_user_profile)){
  for(k in 1:nrow(question_topics)){
    unit_weight_predict_table[k,i]<- cosine(as.numeric(CB_unit_weight[k,]),as.numeric(unit_weight_user_profile[i,]))
  
  }
}
colnames(unit_weight_predict_table) <- rownames(simple_unary_user_profile)
unit_weight_predict_table

```

### likes tables 
```{r}

likes_dislikes <- rbind(sapply(unit_weight_predict_table, function(x){sum(x>0)}))
likes_dislikes <- rbind(likes_dislikes,sapply(unit_weight_predict_table, function(x){sum(x<0)}))
likes_dislikes <- rbind(likes_dislikes,sapply(unit_weight_predict_table, function(x){sum(x==0)}))
rownames(likes_dislikes) <- c("likes", "dislikes","neutral")
likes_dislikes
```
## IDF
### User Profile
```{r}
df <- sapply(question_topics,sum)
df
ldf <- log10(nrow(question_topics)/df)
ldf
idf_user_profile <- data.frame()


for(i in 1:nrow(unit_weight_user_profile)){
  idf_user_profile <- rbind(idf_user_profile,ldf*unit_weight_user_profile[i,])
}
idf_user_profile
```

### predictions
### predictions
```{r}
idf_predict_table <- data.frame()


for(i in 1:nrow(unit_weight_user_profile)){
  for(k in 1:nrow(question_topics)){
    idf_predict_table[k,i]<- cosine(as.numeric(question_topics[k,]),as.numeric(idf_user_profile[i,]))
  
  }
}
colnames(idf_predict_table) <- rownames(simple_unary_user_profile)
idf_predict_table

```

### likes tables 
```{r}

likes_dislikes <- rbind(sapply(idf_predict_table, function(x){sum(x>0)}))
likes_dislikes <- rbind(likes_dislikes,sapply(idf_predict_table, function(x){sum(x<0)}))
likes_dislikes <- rbind(likes_dislikes,sapply(idf_predict_table, function(x){sum(x==0)}))
rownames(likes_dislikes) <- c("likes", "dislikes","neutral")
likes_dislikes
```

## Switched Hybrid
```{r}
answer_score <- apply(answers,1,function(x){sum(x, na.rm = T)})
answers$standardized_answers_score <- (answer_score-mean(answer_score))/sd(answer_score)


idf_average <- apply(idf_predict_table[,1:3],1, mean)
question_score <- 0.9*idf_average+0.1*answers$standardized_answers_score
questions_ratings <- cbind(question_score)
rownames(questions_ratings) <- rownames(question_topics)
sorted_top5<- as.data.frame(sort(questions_ratings[,1], decreasing = T)[1:5])
colnames(sorted_top5)<-"Top 5 Questions"
sorted_top5
```

```{r}
print("all question scores")
questions_ratings
```

## Hybrid Challenge

we created a table that identifies if the user upvoted, downvoted, or answered the question. if the user didn't do any, we considered him as not to have read the question. this is only assumed to create a recommendation system for current users.

```{r}
read_table <- data.frame()
for(i in 1:ncol(feedback)){
  for(k in 1:nrow(feedback)){
  if(!is.na(feedback[k,i]) | !is.na(answers[k,i]) ){
    read_table[k,i] <- 1
  }
    else{
      read_table[k,i]<- 0
    }
  }
}
rownames(read_table) <- rownames(question_topics)
colnames(read_table) <- colnames(idf_predict_table)
read_table
```

for the sake of creating an app and adding more features, we created a random word count for each question. moreover, we also created random dates for those questions, as an extra feature for our app.

```{r}
wordcount <- c(138,244,32,24,423,34,234,235,133,803,578,54,843,564,83,456,668,126,868,38)
x<-Sys.Date()
dates <- c(x-455,x-1,x-1,x-322,x-1,x-157,x-230,x-100,x-455, x-1, x-1, x-56, x-1,x,x-1, x-7,x-1,x-1,x-23, x-1)

wordcount_date <- data.frame(wordcount,dates)
colnames(wordcount_date) <- c("word count", "date posted")
rownames(wordcount_date) <- rownames(question_topics)
wordcount_date
```

in our app, we created a new feature for bathroom reads. this feature includes questions for users where their predicted score is bigger than 0, the wordcount of each question is less than 300 (quick read) and to make sure that the user hasn't seen it before (based on previous assumption).
```{r}
bathroom_pred <- vector()
bathroom_pred_list <- data.frame("dummy" = c(1:20))
predict_table_all_users <- idf_predict_table
predict_table_all_users$User.4<- idf_average


for(i in 1:ncol(predict_table_all_users)){
  for(k in 1:nrow(read_table)){
    if(read_table[k,i]==0 & wordcount[k]<150 & predict_table_all_users[k,i]>0){
      bathroom_pred[k]=predict_table_all_users[k,i]
    }
    else{bathroom_pred[k]=0}
  }
  bathroom_pred_list <- cbind(bathroom_pred_list,bathroom_pred)

}
bathroom_pred_list$dummy <- NULL
colnames(bathroom_pred_list)<- colnames(predict_table_all_users)
rownames(bathroom_pred_list)<-rownames(question_topics)
bathroom_pred_list
```
other than the bathroom feature, we created a commute feature. the commute feature represents questions that usually take more time and therefore makes commute entertaining.

```{r}
commute_pred <- vector()
commute_pred_list <- data.frame("dummy" = c(1:20))
predict_table_all_users <- idf_predict_table
predict_table_all_users$User.4<- idf_average


for(i in 1:ncol(predict_table_all_users)){
  for(k in 1:nrow(read_table)){
    if(read_table[k,i]==0 & wordcount[k]>150 & predict_table_all_users[k,i]>0){
      commute_pred[k]=predict_table_all_users[k,i]
    }
    else{commute_pred[k]=0}
  }
  commute_pred_list <- cbind(commute_pred_list,commute_pred)

}
commute_pred_list$dummy <- NULL
colnames(commute_pred_list)<- colnames(predict_table_all_users)
rownames(commute_pred_list)<-rownames(question_topics)
commute_pred_list
```

and as for our last feature, we created a breakfast feature that includes trending topics from the last 48 hours, taking into considerstion the date column previously created.
```{r}
breakfast_pred <- vector()
breakfast_pred_list <- data.frame("dummy" = c(1:20))
predict_table_all_users <- idf_predict_table
predict_table_all_users$User.4<- idf_average


for(i in 1:ncol(predict_table_all_users)){
  for(k in 1:nrow(read_table)){
    if(read_table[k,i]==0 & dates[k]>(Sys.Date()-2) & predict_table_all_users[k,i]>0){
      breakfast_pred[k]=predict_table_all_users[k,i]
    }
    else{breakfast_pred[k]=0}
  }
  breakfast_pred_list <- cbind(breakfast_pred_list,breakfast_pred)

}
breakfast_pred_list$dummy <- NULL
colnames(breakfast_pred_list)<- colnames(predict_table_all_users)
rownames(breakfast_pred_list)<-rownames(question_topics)
breakfast_pred_list
```